# TLB
快表（TLB, Translation Lookaside Buffer

分页机制中，每次CPU访问内存时，都会先将虚拟地址通过页表映射到物理地址。但访问页表需要查内存，如果每次都查页表，会很慢。TLB 就是一个小型的高速缓存，专门存储**最近使用的虚拟页号到物理页框号的映射**。

具体作用可以总结为：

1. **减少内存访问延迟**：TLB命中时，CPU无需访问主内存的页表，直接得到物理地址，速度非常快。
    
2. **提高分页系统效率**：虚拟地址到物理地址的转换大多数情况下可以在TLB里完成，减少了频繁的内存访问开销。
    
3. **缓存局部性**：程序往往会频繁访问同一片内存页，TLB利用时间和空间局部性提高命中率。
    

如果TLB未命中，CPU才会访问页表，然后将新映射更新到TLB中，以便下次快速访问。

简单理解：**TLB 就像页表的小型高速缓存，让虚拟地址转换变得“快很多”**

是**CPU内部的特殊硬件缓存**，严格来说更接近寄存器的结构。下面详细解释：

1. **性质**
    
    - TLB 是一种**硬件高速缓存**，专门用来存储“虚拟页号 → 物理页框号”的映射。
        
    - 它比普通内存快得多，通常直接集成在 CPU 内部，就像寄存器一样访问速度极快。
        
2. **位置**
    
    - **CPU 内部**：==现代处理器的TLB通常在内存管理单元（MMU, Memory Management Unit）里，是MMU的一部分==。
        
    - **非系统内存**：它不占用主内存空间，也不在操作系统管理的RAM里。
        
3. **作用方式**
    
    - 当CPU需要访问虚拟地址时，先去TLB查找映射，如果找到（TLB命中），就直接得到物理地址。
        
    - 如果找不到（TLB未命中），CPU才去主存的页表查找，然后把查到的映射写入TLB，以备下一次快速访问。

# MMU

**MMU（Memory Management Unit，内存管理单元）通常是CPU的一部分**，或者至少是紧密耦合在CPU内部的硬件模块。具体解释如下：

1. **位置与组成**
    
    - 在现代处理器里，MMU往往集成在CPU芯片内部，与寄存器、ALU等硬件模块一起工作。
        
    - MMU负责处理虚拟地址和物理地址的转换，也就是实现分页和/或分段机制。
        
2. **作用**
    
    - **地址转换**：把CPU生成的虚拟地址映射到物理内存地址。
        
    - **权限检查**：检查访问权限（如用户态/内核态、可读/可写/可执行等）。
        
    - **TLB管理**：TLB就是MMU内部的高速缓存，用于快速查询虚拟页号到物理页框号的映射。
        
3. **关系总结**
    
    - CPU发出虚拟地址 → MMU进行转换 → 如果TLB命中直接给出物理地址 → 如果未命中访问页表 → 返回物理地址。
        
    - 因此，MMU是CPU在硬件层面实现虚拟内存和内存保护的关键模块。


# CPU

CPU 不是只有一个东西，它是一个**复杂的硬件系统**，里面包含了很多不同的模块，每个模块负责不同的工作。可以把CPU想象成一个小型“电脑里的电脑”。


### 1. **算术逻辑单元（ALU, Arithmetic Logic Unit）**

- 负责数学运算和逻辑运算，比如加、减、乘、除，或者比较大小、与或非运算。
    
- 就像CPU的“计算大脑”。
    

### 2. **寄存器（Registers）**

- CPU内部的小型存储单元，用来存临时数据、地址和状态信息。
    
- 速度极快，比内存快很多。
    
- 常见的寄存器：通用寄存器、程序计数器（PC）、堆栈指针（SP）、标志寄存器（FLAGS）等。
    

### 3. **控制单元（CU, Control Unit）**

- 负责控制CPU的各个部分协调工作，告诉ALU做什么、寄存器存什么、内存什么时候读写。
    
- 就像CPU的“指挥官”。
    

### 4. **内存管理单元（MMU, Memory Management Unit）**

- 前面说过，负责**虚拟地址 → 物理地址的转换**，以及权限检查。
    
- 内部通常有TLB，用于快速查页表映射。
    

### 5. **缓存（Cache）**

- CPU内部的小容量高速存储，用来存放常用数据和指令，减少访问主内存的等待。
    
- L1、L2、L3缓存，距离CPU越近越快。
    

### 6. **流水线 & 执行单元**

- 现代CPU为了提高速度，把执行指令拆成多个阶段（取指、译码、执行、访存、写回），这叫**流水线**。
    
- 每个阶段可能有独立的执行单元，比如整数运算单元、浮点运算单元、加载存储单元。
    

### 7. **分支预测 & 指令预取**

- 为了避免流水线停顿，CPU会提前猜测接下来要执行的指令，并提前加载数据。
    
- 如果猜对了，就快；猜错了，就要回滚。